{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron for Single input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Value(-0.5425389782466665)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Value:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Value(self.data + other.data)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return Value(self.data * other.data)\n",
    "\n",
    "    def tanh(self):\n",
    "\n",
    "        from math import tanh\n",
    "\n",
    "        return Value(tanh(self.data))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value({self.data})\"\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, nin):\n",
    "        self.w = [\n",
    "            Value(random.uniform(-1, 0.1)) for _ in range(nin)\n",
    "        ]  \n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "    def __call__(self, x):\n",
    "        act = sum(\n",
    "            ((wi * xi) for wi, xi in zip(self.w, x)), self.b\n",
    "        )  \n",
    "        out = act.tanh() \n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]  \n",
    "\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, nin):\n",
    "        self.neuron = Neuron(nin) \n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.neuron(x)  \n",
    "\n",
    "    def parameters(self):\n",
    "        return self.neuron.parameters()\n",
    "slp = SingleLayerPerceptron(nin=2)\n",
    "\n",
    "\n",
    "inputs = [Value(0), Value(1)]\n",
    "\n",
    "\n",
    "output = slp(inputs)\n",
    "print(f\"Output: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron for Multi Input Model - AND Function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.0, w2 = 0.0, b = -0.1\n",
      "Input: (0, 1) | Prediction: 0 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.0, b = -0.1\n",
      "Input: (1, 0) | Prediction: 0 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.0, b = -0.1\n",
      "Input: (1, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.1, w2 = 0.1, b = 0.0\n",
      "\n",
      "Epoch 2:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.1, w2 = 0.1, b = -0.1\n",
      "Input: (0, 1) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.1, w2 = 0.0, b = -0.2\n",
      "Input: (1, 0) | Prediction: 0 | Error: 0\n",
      "Updated weights: w1 = 0.1, w2 = 0.0, b = -0.2\n",
      "Input: (1, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.2, w2 = 0.1, b = -0.1\n",
      "\n",
      "Testing the trained perceptron:\n",
      "Input: (0, 0) -> Predicted Output: 0\n",
      "Input: (0, 1) -> Predicted Output: 1\n",
      "Input: (1, 0) -> Predicted Output: 1\n",
      "Input: (1, 1) -> Predicted Output: 1\n",
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "     \n",
    "        self.w1 = 0.0\n",
    "        self.w2 = 0.0\n",
    "        self.b = 0.0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "        weighted_sum = self.w1 * x1 + self.w2 * x2 + self.b\n",
    "        return step(weighted_sum)  \n",
    "\n",
    " \n",
    "    def train(self, X, y, epochs=2):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}:\")\n",
    "            for (x1, x2), expected in zip(X, y):\n",
    "                prediction = self.predict(x1, x2)\n",
    "                error = expected - prediction\n",
    "                \n",
    "                self.w1 += self.learning_rate * error * x1\n",
    "                self.w2 += self.learning_rate * error * x2\n",
    "                self.b += self.learning_rate * error\n",
    "             \n",
    "                print(\n",
    "                    f\"Input: ({x1}, {x2}) | Prediction: {prediction} | Error: {error}\"\n",
    "                )\n",
    "                print(f\"Updated weights: w1 = {self.w1}, w2 = {self.w2}, b = {self.b}\")\n",
    "\n",
    "\n",
    "\n",
    "X = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "y = [0, 0, 0, 1]  \n",
    "\n",
    "\n",
    "perceptron = SingleLayerPerceptron(learning_rate=0.1)\n",
    "\n",
    "perceptron.train(X, y, epochs=2)\n",
    "\n",
    "print(\"\\nTesting the trained perceptron:\")\n",
    "results = []\n",
    "for (x1, x2) , expected in zip(X, y):\n",
    "    prediction = perceptron.predict(x1, x2)\n",
    "    results.append((expected,prediction))\n",
    "    print(f\"Input: ({x1}, {x2}) -> Predicted Output: {prediction}\")\n",
    "\n",
    "correct_predictions = sum(1 for expected, prediction in results if expected == prediction)\n",
    "accuracy = correct_predictions / len(results) * 100\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron for OR Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.0, w2 = 0.0, b = -0.1\n",
      "Input: (0, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.0\n",
      "Input: (1, 0) | Prediction: 1 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.0\n",
      "Input: (1, 1) | Prediction: 1 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.0\n",
      "\n",
      "Epoch 2:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = -0.1\n",
      "Input: (0, 1) | Prediction: 1 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = -0.1\n",
      "Input: (1, 0) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.1, w2 = 0.1, b = 0.0\n",
      "Input: (1, 1) | Prediction: 1 | Error: 0\n",
      "Updated weights: w1 = 0.1, w2 = 0.1, b = 0.0\n",
      "\n",
      "Testing the trained perceptron:\n",
      "Input: (0, 0) -> Predicted Output: 1\n",
      "Input: (0, 1) -> Predicted Output: 1\n",
      "Input: (1, 0) -> Predicted Output: 1\n",
      "Input: (1, 1) -> Predicted Output: 1\n",
      "Accuracy: 75.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "\n",
    "        self.w1 = 0.0\n",
    "        self.w2 = 0.0\n",
    "        self.b = 0.0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "        weighted_sum = self.w1 * x1 + self.w2 * x2 + self.b\n",
    "        return step(weighted_sum)\n",
    "\n",
    "    def train(self, X, y, epochs=2):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}:\")\n",
    "            for (x1, x2), expected in zip(X, y):\n",
    "                prediction = self.predict(x1, x2)\n",
    "                error = expected - prediction\n",
    "\n",
    "                self.w1 += self.learning_rate * error * x1\n",
    "                self.w2 += self.learning_rate * error * x2\n",
    "                self.b += self.learning_rate * error\n",
    "\n",
    "                print(\n",
    "                    f\"Input: ({x1}, {x2}) | Prediction: {prediction} | Error: {error}\"\n",
    "                )\n",
    "                print(f\"Updated weights: w1 = {self.w1}, w2 = {self.w2}, b = {self.b}\")\n",
    "\n",
    "\n",
    "X = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "y = [0, 1, 1, 1]\n",
    "\n",
    "\n",
    "perceptron = SingleLayerPerceptron(learning_rate=0.1)\n",
    "\n",
    "perceptron.train(X, y, epochs=2)\n",
    "\n",
    "print(\"\\nTesting the trained perceptron:\")\n",
    "results = []\n",
    "for (x1, x2), expected in zip(X, y):\n",
    "    prediction = perceptron.predict(x1, x2)\n",
    "    results.append((expected, prediction))\n",
    "    print(f\"Input: ({x1}, {x2}) -> Predicted Output: {prediction}\")\n",
    "\n",
    "correct_predictions = sum(\n",
    "    1 for expected, prediction in results if expected == prediction\n",
    ")\n",
    "accuracy = correct_predictions / len(results) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Perceptron for XOR Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = 0.0, w2 = 0.0, b = -0.1\n",
      "Input: (0, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.0\n",
      "Input: (1, 0) | Prediction: 1 | Error: 0\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.0\n",
      "Input: (1, 1) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = -0.1, w2 = 0.0, b = -0.1\n",
      "\n",
      "Epoch 2:\n",
      "Input: (0, 0) | Prediction: 0 | Error: 0\n",
      "Updated weights: w1 = -0.1, w2 = 0.0, b = -0.1\n",
      "Input: (0, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = -0.1, w2 = 0.1, b = 0.0\n",
      "Input: (1, 0) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.1\n",
      "Input: (1, 1) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = -0.1, w2 = 0.0, b = 0.0\n",
      "\n",
      "Epoch 3:\n",
      "Input: (0, 0) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = -0.1, w2 = 0.0, b = -0.1\n",
      "Input: (0, 1) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = -0.1, w2 = 0.1, b = 0.0\n",
      "Input: (1, 0) | Prediction: 0 | Error: 1\n",
      "Updated weights: w1 = 0.0, w2 = 0.1, b = 0.1\n",
      "Input: (1, 1) | Prediction: 1 | Error: -1\n",
      "Updated weights: w1 = -0.1, w2 = 0.0, b = 0.0\n",
      "\n",
      "Testing the trained perceptron:\n",
      "Input: (0, 0) -> Predicted Output: 1\n",
      "Input: (0, 1) -> Predicted Output: 1\n",
      "Input: (1, 0) -> Predicted Output: 0\n",
      "Input: (1, 1) -> Predicted Output: 0\n",
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "\n",
    "class SingleLayerPerceptron:\n",
    "    def __init__(self, learning_rate=0.1):\n",
    "\n",
    "        self.w1 = 0.0\n",
    "        self.w2 = 0.0\n",
    "        self.b = 0.0\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, x1, x2):\n",
    "        weighted_sum = self.w1 * x1 + self.w2 * x2 + self.b\n",
    "        return step(weighted_sum)\n",
    "\n",
    "    def train(self, X, y, epochs=2):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}:\")\n",
    "            for (x1, x2), expected in zip(X, y):\n",
    "                prediction = self.predict(x1, x2)\n",
    "                error = expected - prediction\n",
    "\n",
    "                self.w1 += self.learning_rate * error * x1\n",
    "                self.w2 += self.learning_rate * error * x2\n",
    "                self.b += self.learning_rate * error\n",
    "\n",
    "                print(\n",
    "                    f\"Input: ({x1}, {x2}) | Prediction: {prediction} | Error: {error}\"\n",
    "                )\n",
    "                print(f\"Updated weights: w1 = {self.w1}, w2 = {self.w2}, b = {self.b}\")\n",
    "\n",
    "\n",
    "X = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "y = [0, 1, 1, 0]\n",
    "\n",
    "\n",
    "perceptron = SingleLayerPerceptron(learning_rate=0.1)\n",
    "\n",
    "perceptron.train(X, y, epochs=3)\n",
    "\n",
    "print(\"\\nTesting the trained perceptron:\")\n",
    "results = []\n",
    "for (x1, x2), expected in zip(X, y):\n",
    "    prediction = perceptron.predict(x1, x2)\n",
    "    results.append((expected, prediction))\n",
    "    print(f\"Input: ({x1}, {x2}) -> Predicted Output: {prediction}\")\n",
    "\n",
    "correct_predictions = sum(\n",
    "    1 for expected, prediction in results if expected == prediction\n",
    ")\n",
    "accuracy = correct_predictions / len(results) * 100\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained XOR MLP Output:\n",
      "Input: [0 0] -> Predicted Output: 0.2584, Target: 0\n",
      "Input: [0 1] -> Predicted Output: 0.6914, Target: 1\n",
      "Input: [1 0] -> Predicted Output: 0.6913, Target: 1\n",
      "Input: [1 1] -> Predicted Output: 0.3987, Target: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_input_hidden = np.random.uniform(size=(2, 2))\n",
    "weights_hidden_output = np.random.uniform(size=(2, 1))\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "for epoch in range(10000):\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden)\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "    predicted_output = sigmoid(output_layer_input)\n",
    "\n",
    "    error = y - predicted_output\n",
    "\n",
    "    \n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "\n",
    "    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "\n",
    "    weights_hidden_output += (\n",
    "        hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "    )\n",
    "    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate\n",
    "\n",
    "print(\"Trained XOR MLP Output:\")\n",
    "for inputs, target in zip(X, y):\n",
    "    hidden_layer_output = sigmoid(np.dot(inputs, weights_input_hidden))\n",
    "    predicted_output = sigmoid(np.dot(hidden_layer_output, weights_hidden_output))\n",
    "    print(\n",
    "        f\"Input: {inputs} -> Predicted Output: {predicted_output[0]:.4f}, Target: {target[0]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
